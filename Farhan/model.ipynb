{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import logging\n",
    "from datasets import load_dataset\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import google.generativeai as genai\n",
    "from google.oauth2 import service_account\n",
    "from pydantic import BaseModel, Field\n",
    "from rouge_score import rouge_scorer\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\farha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\farha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\farha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK resources\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the service account's JSON file\n",
    "service_account_path = \"adv-nlp-uts-faa7595a22eb.json\"\n",
    "\n",
    "# Create credentials using the service account JSON file\n",
    "try:\n",
    "    credentials = service_account.Credentials.from_service_account_file(service_account_path, scopes=[\"https://www.googleapis.com/auth/generative-language\"])\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"Service account file not found at {service_account_path}.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error creating credentials from the service account file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Configure the Gemini API client with the credentials\n",
    "genai.configure(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text preprocessing function with lemmatization\n",
    "def preprocess_text(text):\n",
    "    # 1. Strip whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    # 2. Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # 3. Remove stopwords and apply lemmatization\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # 4. Join the tokens back into a string\n",
    "    preprocessed_text = \" \".join(lemmatized_tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mental health conversations dataset\n",
    "# dataset = load_dataset(\"RafaelMPereira/HealthCareMagic-100k-Chat-Format-en\")\n",
    "dataset = load_dataset(\"Amod/mental_health_counseling_conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'Context' and 'Response' into 'text' field and preprocess\n",
    "def process_entry(entry):\n",
    "    combined_text = f\"Context: {entry['Context']}\\nResponse: {entry['Response']}\"\n",
    "    return {\"text\": preprocess_text(combined_text)}\n",
    "\n",
    "\n",
    "processed_data = [process_entry(entry) for entry in dataset[\"train\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents into chunks if necessary (e.g., max 512 tokens)\n",
    "def chunk_text(text, max_length=512):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    chunks = [\" \".join(tokens[i : i + max_length]) for i in range(0, len(tokens), max_length)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Total number of documents after chunking: 3526\n"
     ]
    }
   ],
   "source": [
    "# Create a list of documents for embedding\n",
    "documents = []\n",
    "for item in processed_data:\n",
    "    chunks = chunk_text(item[\"text\"])\n",
    "    documents.extend(chunks)\n",
    "\n",
    "logger.info(f\"Total number of documents after chunking: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farha\\AppData\\Local\\Temp\\ipykernel_24992\\1440661554.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "c:\\Users\\farha\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the embeddings model\n",
    "embedding_model_name = \"all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# Initialize FAISS vector store\n",
    "vector_store = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "# Save the vector store locally\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "# Load the vector store from disk\n",
    "# vector_store = FAISS.load_local(\"faiss_index\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the Gemini LLM class\n",
    "class GeminiLLM(LLM, BaseModel):\n",
    "    model_name: str = Field(default=\"gemini-1.5-flash\")\n",
    "    temperature: float = Field(default=0.7)\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"gemini\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: list[str] = None) -> str:\n",
    "        try:\n",
    "            # Initialize the model\n",
    "            model = genai.GenerativeModel(model_name=self.model_name)\n",
    "\n",
    "            # Generate content using the Gemini API\n",
    "            response = model.generate_content(\n",
    "                prompt,\n",
    "                # temperature=self.temperature,\n",
    "                # max_output_tokens=512  # The text prompt to generate content from  # Adjust token limit as needed\n",
    "            )\n",
    "\n",
    "            # Extract generated text from the response\n",
    "            generated_text = response.text\n",
    "\n",
    "            # Handle stop tokens if provided\n",
    "            if stop:\n",
    "                for token in stop:\n",
    "                    generated_text = generated_text.split(token)[0]\n",
    "\n",
    "            return generated_text.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Gemini API error: {e}\")\n",
    "            return \"I'm sorry, but I couldn't process your request at this time.\"\n",
    "\n",
    "\n",
    "# Initialize the Gemini LLM client\n",
    "llm = GeminiLLM(model_name=\"gemini-1.5-flash\", temperature=0.7)\n",
    "\n",
    "# Define a prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a helpful mental health assistant.\n",
    "\n",
    "Use the following context to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RetrievalQA chain with the custom prompt\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # You can experiment with 'refine' or 'map_reduce'\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    chain_type_kwargs={\"prompt\": prompt_template},\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle user queries\n",
    "def answer_query(query):\n",
    "    try:\n",
    "        response = qa_chain({\"query\": query})\n",
    "        answer = response[\"result\"]\n",
    "        source_docs = response[\"source_documents\"]\n",
    "        print(\"Response:\")\n",
    "        print(answer)\n",
    "        print(\"\\nRelevant Source Documents:\")\n",
    "        for doc in source_docs:\n",
    "            print(doc.metadata.get(\"source\", \"Unknown Source\"))\n",
    "            print(doc.page_content)\n",
    "            print(\"-\" * 80)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during query processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farha\\AppData\\Local\\Temp\\ipykernel_24992\\1582395274.py:4: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Dealing with anxiety effectively involves a combination of short-term coping mechanisms and long-term solutions. Here are some tips based on the provided context:\n",
      "\n",
      "**Short-Term Coping:**\n",
      "\n",
      "* **Distraction:** Engage in activities that occupy your mind like listening to audiobooks, counting backward, or naming cities.\n",
      "* **Physical Sensations:** Holding an ice pack or using soothing self-talk can help ground you and remind you that you can handle the situation.\n",
      "* **Deep Breathing:** Practice deep abdominal breathing, which can help calm your body and mind.\n",
      "\n",
      "**Long-Term Solutions:**\n",
      "\n",
      "* **Therapy:** Seek professional help from a therapist specializing in anxiety disorders. They can provide personalized guidance and coping strategies.\n",
      "* **Mindfulness:** Incorporate daily mindfulness practices like guided meditation, yoga, or deep breathing exercises to develop awareness and manage stress.\n",
      "* **Positive Self-Talk:** Challenge negative thoughts by replacing them with positive affirmations. Remind yourself that you can handle the situation and that you are strong.\n",
      "* **Exposure Therapy:** With the support of a mental health professional, gradually expose yourself to situations that trigger anxiety. This helps desensitize you over time.\n",
      "\n",
      "**Important Note:** Remember that anxiety is treatable. While these tips can be helpful, it's crucial to seek professional support for long-term management and to address any underlying issues that may be contributing to your anxiety.\n",
      "\n",
      "Relevant Source Documents:\n",
      "Unknown Source\n",
      "context : get much anxiety , ’ know . feel like ’ anything ’ scared outcome . response : common question practice . panic attack typically emerge underlying issue ( ex . depression , low self-esteem , fear ) . decrease anxiety symptom ’ recommended seek treatment therapist specializes working anxiety disorder importantly one feel comfortable with.in practice educate client anxiety discus building framework helpful tool decreasing anxiety:1 . starting daily mindfulness practice . example : listening guided meditation ; engaging deep breathing exercise ; yoga practice ; positive calming activities.2 . understand negative positive thought . many time tend focus potential bad thing happen . increase positive self-talk feeling anxious . example : `` n't need worry , calm relaxed `` . 3 . exposure fearful anxious situation . accomplished care mental health professional . many time shy away thing make u feel uncomfortable insecure . may led increase isolating behavior resulting difficulty performing thing able . example : leaving house ; presenting front others ; going social event ; conversation people . however , expose practice use positive coping skill ( ex . deep breathing ) chance anxiety decrease . hope helpful . keep mind , therapist help guiding self relaxation improvement .\n",
      "--------------------------------------------------------------------------------\n",
      "Unknown Source\n",
      "context : get much anxiety , ’ know . feel like ’ anything ’ scared outcome . response : common question practice . panic attack typically emerge underlying issue ( ex . depression , low self-esteem , fear ) . decrease anxiety symptom ’ recommended seek treatment therapist specializes working anxiety disorder importantly one feel comfortable with.in practice educate client anxiety discus building framework helpful tool decreasing anxiety:1 . starting daily mindfulness practice . example : listening guided meditation ; engaging deep breathing exercise ; yoga practice ; positive calming activities.2 . understand negative positive thought . many time tend focus potential bad thing happen . increase positive self-talk feeling anxious . example : `` n't need worry , calm relaxed `` . 3 . exposure fearful anxious situation . accomplished care mental health professional . many time shy away thing make u feel uncomfortable insecure . may led increase isolating behavior resulting difficulty performing thing able . example : leaving house ; presenting front others ; going social event ; conversation people . however , expose practice use positive coping skill ( ex . deep breathing ) chance anxiety decrease . hope helpful . keep mind , therapist help guiding self relaxation improvement .\n",
      "--------------------------------------------------------------------------------\n",
      "Unknown Source\n",
      "context : 'm teenager , ’ never kind therapist , noticed experience several anxiety symptom . frequently find going following parent around house . ca n't go store ( grocery store specifically ) , , phone dad whole time . also forget thing lot . response : despite anxiety highly attuned sense well skillful articulating detail anxiety take over.sometimes people anxious specific realtime situation helped talking anxiety.maybe 'd able distract grocery store anxiety telling 're anxious 'll ok , grocery store.the longer term way dissolve anxiety self-acceptance , self-love , self-belief , basically area trusting handle situations.anxiety fear overwhelmed circumstance condition end badly you.often person well handle situation 're anxious . problem trusting enough rely self knowledge .\n",
      "--------------------------------------------------------------------------------\n",
      "Unknown Source\n",
      "context : took job requires travel far away home . family really need job . people keep telling `` anxiety `` 'm terrified anxiety attack road . new . ? response : anxiety panic attack frightening . `` tool `` use help short term : keeping mind occupied listening book tape may help ; counting backwards 100 7 's ; naming city begin letter alphabet ; keeping ice ice pack cooler beside , may take hold hand face ; soothing self-talk `` uncomfortable , handle `` `` 've make `` . recommend seek therapist help long-term solution anxiety . additionally , learning breathe abdomen practicing daily another long-term solution . yoga meditation would great !\n",
      "--------------------------------------------------------------------------------\n",
      "Unknown Source\n",
      "context : took job requires travel far away home . family really need job . people keep telling `` anxiety `` 'm terrified anxiety attack road . new . ? response : anxiety panic attack frightening . `` tool `` use help short term : keeping mind occupied listening book tape may help ; counting backwards 100 7 's ; naming city begin letter alphabet ; keeping ice ice pack cooler beside , may take hold hand face ; soothing self-talk `` uncomfortable , handle `` `` 've make `` . recommend seek therapist help long-term solution anxiety . additionally , learning breathe abdomen practicing daily another long-term solution . yoga meditation would great !\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG system with a query\n",
    "query = \"How can someone deal with anxiety effectively?\"\n",
    "answer_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "def evaluate_rouge(predicted, reference):\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rougeL\"], use_stemmer=True)\n",
    "    return scorer.score(reference, predicted)\n",
    "\n",
    "\n",
    "def evaluate_bleu(predicted, reference):\n",
    "    bleu = sacrebleu.corpus_bleu([predicted], [[reference]])\n",
    "    return bleu.score\n",
    "\n",
    "\n",
    "def evaluate_f1(predicted, reference):\n",
    "    predicted_tokens = nltk.word_tokenize(preprocess_text(predicted))\n",
    "    reference_tokens = nltk.word_tokenize(preprocess_text(reference))\n",
    "    common_tokens = set(predicted_tokens) & set(reference_tokens)\n",
    "\n",
    "    precision = len(common_tokens) / len(predicted_tokens) if predicted_tokens else 0\n",
    "    recall = len(common_tokens) / len(reference_tokens) if reference_tokens else 0\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "def run_evaluation(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rouge_scores, bleu_scores, f1_scores = [], [], []\n",
    "\n",
    "    for entry in data:\n",
    "        question = entry[\"question\"]\n",
    "        reference_answer = entry[\"answer\"]\n",
    "        predicted_answer = answer_query(question)\n",
    "\n",
    "        rouge = evaluate_rouge(predicted_answer, reference_answer)\n",
    "        bleu = evaluate_bleu(predicted_answer, reference_answer)\n",
    "        f1 = evaluate_f1(predicted_answer, reference_answer)\n",
    "\n",
    "        rouge_scores.append(rouge[\"rougeL\"].fmeasure)\n",
    "        bleu_scores.append(bleu)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Q: {question}\")\n",
    "        print(f\"Predicted: {predicted_answer}\")\n",
    "        print(f\"Reference: {reference_answer}\")\n",
    "        print(f\"ROUGE-L: {rouge}\")\n",
    "        print(f\"BLEU: {bleu}\")\n",
    "        print(f\"F1: {f1}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    print(\"\\n=== Evaluation Summary ===\")\n",
    "    print(f\"Average ROUGE-L: {sum(rouge_scores) / len(rouge_scores):.4f}\")\n",
    "    print(f\"Average BLEU: {sum(bleu_scores) / len(bleu_scores):.2f}\")\n",
    "    print(f\"Average F1: {sum(f1_scores) / len(f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_evaluation(\"questions_answers.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
